# replace weights_directory with either:
# * the *ABSOLUTE PATH* to where you store your weights, or
# * the huggingface repo with your weights
[llama-13b]
weights_directory = /share/u/smarks/llama_from_lambda/13B
huggingface_token = sample
name = LLaMA-13B
probe_layer = 13
intervene_layer = 7
noperiod = False
[llama-2-13b]
weights_directory = meta-llama/Llama-2-13b-hf
huggingface_token = sample
name = LLaMA-2-13B
probe_layer = 14
intervene_layer = 8
noperiod = False
[llama-3-8b]
weights_directory = meta-llama/Meta-Llama-3-8B
huggingface_token = sample
name = LLaMA-3-8B
probe_layer = 12
intervene_layer = 8
noperiod = False
[llama-2-70b]
weights_directory = meta-llama/Llama-2-70b-hf
huggingface_token = sample
name = LLaMA-2-13B
intervene_layer = 8
probe_layer = 27
noperiod = False

[llama-2-7b]
weights_directory = meta-llama/Llama-2-7b-hf
huggingface_token = sample
name = LLaMA-2-7B
probe_layer = 13
noperiod = False

[llama-2-13b-reset]
weights_directory = meta-llama/Llama-2-13b-hf
huggingface_token = sample
name = LLaMA-2-13B-reset
probe_layer = 14
intervene_layer = 8
noperiod = False